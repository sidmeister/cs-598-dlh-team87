{"cells":[{"cell_type":"code","execution_count":14,"id":"6e66e77a","metadata":{},"outputs":[],"source":"from biobert_embedding.embedding import BiobertEmbedding\nfrom scipy.spatial import distance\nimport pandas as pd\nimport os"},{"cell_type":"code","execution_count":15,"id":"be398526","metadata":{},"outputs":[],"source":"ner_df = pd.read_pickle(\"data/ner_df.p\")\n"},{"cell_type":"code","execution_count":17,"id":"d6949c64","metadata":{},"outputs":[],"source":"null_index_list = []\nfor i in ner_df.itertuples():\n    if len(i.ner) == 0:\n        null_index_list.append(i.Index)\nner_df.drop(null_index_list, inplace=True)"},{"cell_type":"code","execution_count":23,"id":"6e0dd827","metadata":{},"outputs":[],"source":"print(len(ner_df))"},{"cell_type":"code","execution_count":null,"id":"5e505fe1","metadata":{},"outputs":[],"source":"count = 0\nbiobert = BiobertEmbedding(\"/home/ubuntu/biobertmodel\")\n\nnew_biobert_dict = {}\nwith open(\"/home/ubuntu/bad_vectors.txt\", \"w\") as file1:\n    # Writing data to a file\n    sentence_vector = \"\"\n    num_exceptions = 0\n    for i in ner_df.itertuples():\n        # print(i)\n        if count % 1000 == 0:\n            print(f\"processed {count} with exceptions: {num_exceptions}\")\n        if i.preprocessed_text is not None and len(i.preprocessed_text[0]) > 0:\n            try:\n                # print(i.preprocessed_text[0])\n                sentence_vector = biobert.sentence_vector(i.preprocessed_text[0])\n                if i.SUBJECT_ID not in new_biobert_dict:\n                    new_biobert_dict[i.SUBJECT_ID] = list(sentence_vector)            \n                else:\n                    new_biobert_dict[i.SUBJECT_ID].append(sentence_vector) \n            except Exception as e:\n                print(str(e))\n                num_exceptions += 1\n                file1.write(f\"error on subject: {i.SUBJECT_ID}    {i.preprocessed_text[0]}\" + \"\\n\")\n                unique_keywords = dict()\n                to_sentence = list()\n                for list_of_tuples in i.ner:\n                    for a_tuple in list_of_tuples:\n                        if a_tuple[0] not in unique_keywords:\n                            unique_keywords[a_tuple[0]] = a_tuple[1]\n                            to_sentence.append(a_tuple[0])\n                            to_sentence.append(a_tuple[1])\n                \n                to_sentence = [word.strip() for word in to_sentence]\n                \n                if i.SUBJECT_ID not in new_biobert_dict:\n                    new_biobert_dict[i.SUBJECT_ID] = list(' '.join(to_sentence))            \n                else:\n                    new_biobert_dict[i.SUBJECT_ID].append(' '.join(to_sentence)) \n                    \n        count += 1\n    \n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"pd.to_pickle(new_biobert_dict, \"data/biobert_test_data.pkl\")"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}