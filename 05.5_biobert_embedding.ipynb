{"cells":[{"cell_type":"code","execution_count":14,"id":"6e66e77a","metadata":{},"outputs":[],"source":"from biobert_embedding.embedding import BiobertEmbedding\nfrom scipy.spatial import distance\nimport pandas as pd\nimport os"},{"cell_type":"code","execution_count":15,"id":"be398526","metadata":{},"outputs":[],"source":"ner_df = pd.read_pickle(\"data/ner_df.p\")\n"},{"cell_type":"code","execution_count":17,"id":"d6949c64","metadata":{},"outputs":[],"source":"null_index_list = []\nfor i in ner_df.itertuples():\n    if len(i.ner) == 0:\n        null_index_list.append(i.Index)\nner_df.drop(null_index_list, inplace=True)"},{"cell_type":"code","execution_count":23,"id":"6e0dd827","metadata":{},"outputs":[],"source":"print(len(ner_df))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def handle_truncate_list(key, sentence_vector, my_dict, max_items_in_list =3):\n    if key in my_dict: \n        \n        # we must do some logic to remove the most similar item\n        if len(my_dict[key]) == max_items_in_list: \n            my_list  = my_dict[key]\n            similarity_value = 0.00\n            index = -1\n            for i, vector_to_compare in enumerate(my_list):\n                cosine_sim = 1 - distance.cosine(sentence_vector, vector_to_compare)\n                if cosine_sim > similarity_value:\n                    index = i\n                    similarity_value = cosine_sim\n            if index > -1:\n                my_dict[key].pop(index)\n    else:\n        my_dict[key] = list()\n    \n    my_dict[key].append(sentence_vector)"},{"cell_type":"code","execution_count":null,"id":"5e505fe1","metadata":{},"outputs":[],"source":"count = 0\nbiobert = BiobertEmbedding(\"/home/ubuntu/biobertmodel\")\n\nnew_biobert_dict = {}\nwith open(\"/home/ubuntu/bad_vectors.txt\", \"w\") as file1:\n    # Writing data to a file\n    sentence_vector = \"\"\n    num_exceptions = 0\n    for i in ner_df.itertuples():\n        # print(i)\n        \n        # we should only look for ids that are relevant\n        if i.SUBJECT_ID not in ner_fasttext:\n            continue\n            \n        if count % 1000 == 0:\n            print(f\"processed {count} with exceptions: {num_exceptions}\")\n        if i.preprocessed_text is not None and len(i.preprocessed_text[0]) > 0:\n            try:\n                # print(i.preprocessed_text[0])\n                sentence_vector = biobert.sentence_vector(i.preprocessed_text[0])\n                handle_truncate_list(i.SUBJECT_ID, sentence_vector, new_biobert_dict)\n                #if i.SUBJECT_ID not in new_biobert_dict:\n                 #   new_biobert_dict[i.SUBJECT_ID] = list(sentence_vector)            \n                #else:\n                 #   new_biobert_dict[i.SUBJECT_ID].append(sentence_vector) \n            except Exception as e:\n                print(str(e))\n                num_exceptions += 1\n                file1.write(f\"error on subject: {i.SUBJECT_ID}    {i.preprocessed_text[0]}\" + \"\\n\")\n                unique_keywords = dict()\n                to_sentence = list()\n                for list_of_tuples in i.ner:\n                    for a_tuple in list_of_tuples:\n                        if a_tuple[0] not in unique_keywords:\n                            unique_keywords[a_tuple[0]] = a_tuple[1]\n                            to_sentence.append(a_tuple[0])\n                            to_sentence.append(a_tuple[1])\n                \n                to_sentence = [word.strip() for word in to_sentence]\n                sentence_vector = biobert.sentence_vector(' '.join(to_sentence))\n                \n                handle_truncate_list(i.SUBJECT_ID, sentence_vector, new_biobert_dict)\n                \n                #if i.SUBJECT_ID not in new_biobert_dict:\n                 #   new_biobert_dict[i.SUBJECT_ID] = list(' '.join(to_sentence))            \n                #else:\n                #    new_biobert_dict[i.SUBJECT_ID].append(' '.join(to_sentence)) \n                    \n        count += 1\n    \n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"pd.to_pickle(new_biobert_dict, \"data/biobert_test_data.pkl\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"len(list(new_biobert_dict.keys()))"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}