{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"import pandas as pd\nimport os\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\ndef mean(a):\n    return sum(a) / len(a)"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"lvl2_train =  pd.read_pickle(\"data/lvl2_imputer_train.pkl\")\nlvl2_dev =  pd.read_pickle(\"data/lvl2_imputer_dev.pkl\")\nlvl2_test =  pd.read_pickle(\"data/lvl2_imputer_test.pkl\")\n\nYs =  pd.read_pickle(\"data/Ys.pkl\")\nYs_train =  pd.read_pickle(\"data/Ys_train.pkl\")\nYs_dev =  pd.read_pickle(\"data/Ys_dev.pkl\")\nYs_test =  pd.read_pickle(\"data/Ys_test.pkl\")"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"all_train_ids = set()\nfor i in Ys_train.itertuples():\n    all_train_ids.add( i.Index[0] )\n    \nall_dev_ids = set()\nfor i in Ys_dev.itertuples():\n    all_dev_ids.add( i.Index[0] )\n    \nall_test_ids = set()\nfor i in Ys_test.itertuples():\n    all_test_ids.add( i.Index[0] )"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"print (sum(Ys_train.mort_icu.values)*1.0 / len(Ys_train.mort_icu.values))\nprint (sum(Ys_dev.mort_icu.values)*1.0 / len(Ys_dev.mort_icu.values))\nprint (sum(Ys_test.mort_icu.values)*1.0 / len(Ys_test.mort_icu.values))\nprint (\"====\")\nprint (sum(Ys_train.mort_hosp.values)*1.0 / len(Ys_train.mort_hosp.values))\nprint (sum(Ys_dev.mort_hosp.values)*1.0 / len(Ys_dev.mort_hosp.values))\nprint (sum(Ys_test.mort_hosp.values)*1.0 / len(Ys_test.mort_hosp.values))\nprint (\"====\")\nprint (sum(Ys_train.los_3.values)*1.0 / len(Ys_train.los_3.values))\nprint (sum(Ys_dev.los_3.values)*1.0 / len(Ys_dev.los_3.values))\nprint (sum(Ys_test.los_3.values)*1.0 / len(Ys_test.los_3.values))\nprint (\"====\")\nprint (sum(Ys_train.los_7.values)*1.0 / len(Ys_train.los_7.values))\nprint (sum(Ys_dev.los_7.values)*1.0 / len(Ys_dev.los_7.values))\nprint (sum(Ys_test.los_7.values)*1.0 / len(Ys_test.los_7.values))"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"new_word2vec_dict = pd.read_pickle(\"data/new_ner_word2vec_limited_dict.pkl\")"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"new_word2vec_dict = pd.read_pickle(\"data/new_ner_word2vec_limited_dict.pkl\")\nnew_keys = set(new_word2vec_dict.keys())\nnew_train_ids = sorted(all_train_ids.intersection(new_keys))\nnew_dev_ids = sorted(all_dev_ids.intersection(new_keys))\nnew_test_ids = sorted(all_test_ids.intersection(new_keys))"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"pd.to_pickle(new_train_ids, \"data/new_train_ids.pkl\")\npd.to_pickle(new_dev_ids, \"data/new_dev_ids.pkl\")\npd.to_pickle(new_test_ids, \"data/new_test_ids.pkl\")"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"new_train_ids = pd.read_pickle(\"data/new_train_ids.pkl\")\nnew_dev_ids = pd.read_pickle(\"data/new_dev_ids.pkl\")\nnew_test_ids = pd.read_pickle(\"data/new_test_ids.pkl\")"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"data_ids = [(new_train_ids, new_dev_ids, new_test_ids)]\ndata_names = [\"new\"]\n\nfor i, (tr, de, te) in zip(data_names, data_ids):\n    \n    y_train = Ys_train.loc[tr]\n    y_dev = Ys_dev.loc[de]\n    y_test = Ys_test.loc[te]\n\n    sub_train = lvl2_train.loc[tr]\n    sub_train = sub_train.loc[:, pd.IndexSlice[:, 'mean']]\n\n    sub_dev = lvl2_dev.loc[de]\n    sub_dev = sub_dev.loc[:, pd.IndexSlice[:, 'mean']]\n\n    sub_test = lvl2_test.loc[te]\n    sub_test = sub_test.loc[:, pd.IndexSlice[:, 'mean']]\n\n    sub_train = sub_train.to_numpy()\n    sub_dev = sub_dev.to_numpy()\n    sub_test = sub_test.to_numpy()\n\n    # reshape the data for timeseries prediction\n    x_train_lstm = sub_train.reshape(int(sub_train.shape[0] / 24), 24, 104)\n    x_dev_lstm = sub_dev.reshape(int(sub_dev.shape[0] / 24), 24, 104)\n    x_test_lstm = sub_test.reshape(int(sub_test.shape[0] / 24), 24, 104)\n\n    \n    pd.to_pickle(x_train_lstm, \"data/\"+i+\"_x_train.pkl\")\n    pd.to_pickle(x_dev_lstm, \"data/\"+i+\"_x_dev.pkl\")\n    pd.to_pickle(x_test_lstm, \"data/\"+i+\"_x_test.pkl\")\n    \n    pd.to_pickle(y_train, \"data/\"+i+\"_y_train.pkl\")\n    pd.to_pickle(y_dev, \"data/\"+i+\"_y_dev.pkl\")\n    pd.to_pickle(y_test, \"data/\"+i+\"_y_test.pkl\")"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}